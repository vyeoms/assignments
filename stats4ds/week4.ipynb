{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244f4576",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec0fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy as scp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d3c026",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "## Part A\n",
    "\n",
    "The confusion matrix for the exercise looks like this:\n",
    "\n",
    "| Proportion  | H0 retained | H0 rejected   |\n",
    "| :---:       |    :----:   |          :---:|\n",
    "| H0 true     | TN          | FP (Type I)   |\n",
    "| H1 true     | FN (Type II)|       TP      |\n",
    "\n",
    "With the definitions given in the lectures for $\\alpha$ and $\\beta$, we have that each proportion may be determined by:\n",
    "\n",
    "$$\n",
    "TN = n_0 (1-\\alpha)\\\\\n",
    "FP = \\alpha n_0\\\\\n",
    "FN = n_1(1-\\beta)\\\\\n",
    "TP = \\beta n_1\n",
    "$$\n",
    "\n",
    "Where $n_0$ is the number of hypotheses that are true ($H_0$) and $n_1$ is the number of hypotheses that are false ($H_1$). Then the probability that $H_1$ is true given that $H_0$ is rejected is given by the proportion:\n",
    "\n",
    "$$ \\frac{TP}{TP + FP} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5247eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations with alpha=0.05, beta=0.8, n0=100, n1=100\n",
      "P(H1|H0 rejected): 0.9411764705882353\n",
      "Calculations with alpha=0.05, beta=0.5, n0=100, n1=100\n",
      "P(H1|H0 rejected): 0.9090909090909091\n",
      "Calculations with alpha=0.05, beta=0.2, n0=100, n1=100\n",
      "P(H1|H0 rejected): 0.8\n",
      "Calculations with alpha=0.05, beta=0.8, n0=900, n1=100\n",
      "P(H1|H0 rejected): 0.64\n",
      "Calculations with alpha=0.05, beta=0.5, n0=900, n1=100\n",
      "P(H1|H0 rejected): 0.5263157894736842\n",
      "Calculations with alpha=0.05, beta=0.2, n0=900, n1=100\n",
      "P(H1|H0 rejected): 0.3076923076923077\n",
      "Calculations with alpha=0.05, beta=0.8, n0=99900, n1=100\n",
      "P(H1|H0 rejected): 0.015763546798029555\n"
     ]
    }
   ],
   "source": [
    "def calculateProps(alpha, beta, n0, n1):\n",
    "    print(f'Calculations with alpha={alpha}, beta={beta}, n0={n0}, n1={n1}')\n",
    "#     print(f'TN = {n0*(1-alpha)}')\n",
    "#     print(f'FP = {alpha*n0}')\n",
    "#     print(f'FN = {n1*(1-beta)}')\n",
    "#     print(f'TP = {beta*n1}')\n",
    "    TP = beta*n1\n",
    "    FP = alpha*n0\n",
    "    print(f'P(H1|H0 rejected): {TP/(TP+FP)}')\n",
    "\n",
    "props = [(100, 100), (900, 100)]\n",
    "betas = [0.8, 0.5, 0.2]\n",
    "\n",
    "for prop in props:\n",
    "    for beta in betas:\n",
    "        calculateProps(0.05, beta, prop[0], prop[1])\n",
    "calculateProps(0.05, 0.8, 99900, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63dba5a",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "The probabilities where the populations of true $H_0$ and $H_1$ are similar are high, which is what we would like to see when we reject the null hypothesis. These probabilities also become lower when the power of the test decreases. The definition of power is \"the probability that $H_0$ is rejected when $H_0$ is false\", so this result is also expected.\n",
    "\n",
    "However, when we skew the proportion of hypothesis results toward $H_0$ we can see that the probabilities drop drastically. This shows one of the weaknesses of NHST, where if we have underrepresented groups of data we will not get accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e7e89",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d09a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9446199162650353\n",
      "7.979997860951826e-05\n",
      "7.992664956146811e-05\n"
     ]
    }
   ],
   "source": [
    "def waldStat(x, y):\n",
    "    return ( np.mean(x) - np.mean(y) ) / np.sqrt( np.var(x)/x.size + np.var(y)/y.size )\n",
    "\n",
    "def waldP(x_lim):\n",
    "    return 2*(1 - scp.stats.norm.cdf(x_lim))\n",
    "\n",
    "twain = np.array([.225, .262, .217, .240, .230, .229, .235, .217])\n",
    "snodgrass = np.array( [.209, .205, .196, .210, .202, .207, .224, .223, .220, .201] )\n",
    "print( waldStat(twain, snodgrass) )\n",
    "print(waldP(3.945))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc63dbd",
   "metadata": {},
   "source": [
    "The Wald statistic for this test is approximately 3.945. The rejection region is defined by $R = \\{|Z| > 3.945\\}$, where Z corresponds to the Wald statistic. Thus, the p-value is given by:\n",
    "\n",
    "$$ P\\left( |Z| > 3.945 \\right) = 2\\cdot P\\left(Z > 3.945 \\right) = 2 \\cdot \\left( 1 - P(Z \\leq 3.945) \\right) = 2\\cdot (1 - \\Phi(3.945) ) $$\n",
    "\n",
    "because the distribution of Z is approximately normal with mean 0 and variance 1 for a Wald test. For a normal distribution, this probability is given by:\n",
    "\n",
    "$$ 2\\cdot \\left(1 - \\int_{-\\infty}^{3.945} \\frac{1}{\\sqrt{2\\pi}} e^{ -\\frac{x^2}{2} } dx \\right) = 2\\cdot(1-\\Phi(3.945))  \\approx 0.0000798 $$\n",
    "\n",
    "The confidence interval is given by $\\overline{X} - \\overline{Y} \\pm 2\\sqrt{ \\frac{s_1^2}{8} + \\frac{s_2^2}{10} } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff2e0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_mean - Y_mean, with X being Twain and Snodgrass Y: 0.022175\n",
      "Sample variance metric: 0.011243161810629607\n",
      "Confidence interval: [0.010931838189370394, 0.03341816181062961]\n"
     ]
    }
   ],
   "source": [
    "mean_diff = np.mean(twain) - np.mean(snodgrass)\n",
    "var_metric = 2*np.sqrt( np.var(twain)/twain.size + np.var(snodgrass)/snodgrass.size )\n",
    "conf_interval = [ mean_diff - var_metric, mean_diff + var_metric]\n",
    "\n",
    "print(f'X_mean - Y_mean, with X being Twain and Snodgrass Y: {mean_diff}')\n",
    "\n",
    "print(f'Sample variance metric: {var_metric}')\n",
    "\n",
    "print(f'Confidence interval: {conf_interval}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb8263",
   "metadata": {},
   "source": [
    "The p-value indicates that the result is statistically significant, but the confidence interval $(0.1, 0.3)$ is small. Since the confidence interval is so small, you could argue that the authors aren't different people\n",
    "\n",
    "## Part B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02624b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008999100089991002\n"
     ]
    }
   ],
   "source": [
    "B = 10000\n",
    "p_val = 1/(B+1)\n",
    "permute_space = np.concatenate( (twain, snodgrass) )\n",
    "\n",
    "npr.seed(0)\n",
    "for i in range(B):\n",
    "    permute = npr.permutation(permute_space)\n",
    "    p_val += ( waldStat( permute[:8], permute[8:] ) > 3.945 ) / (B+1)\n",
    "\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd124e8b",
   "metadata": {},
   "source": [
    "The p-value using permutation testing is almost 10 times bigger than the one calculated in the previous section, so the evidence against the null is weaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577356fc",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "## Part A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f1bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

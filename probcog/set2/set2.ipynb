{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Data Science  \n",
    "DATA20047 Probabilistic Cognitive Modelling - Spring 2023  \n",
    "Luigi Acerbi  \n",
    "\n",
    "# Problem Set 2: Response distribution and model fitting\n",
    "\n",
    "- This homework problem set focuses on **Week 3 and 4** of the course.\n",
    "- This problem set is worth **25 points** in total (out of 100 for the full course).\n",
    "- Check the submission deadline on Moodle! **Note that the deadline is at noon.**\n",
    "\n",
    "\n",
    "## Submission instructions\n",
    "\n",
    "Submission must be perfomed entirely on Moodle (**not** by email).\n",
    "1. When you have completed the exercises, save the notebook.\n",
    "2. Report your solutions and answers on Moodle (\"*Problem set 2 answer return*\").\n",
    "3. Submit two files on Moodle (\"*Problem set 2 notebook return*\"): \n",
    "  - The notebook as `.ipynb`.\n",
    "  - The same notebook downloaded as `.pdf` (there are various ways to save the file as PDF, the most general is \"File\" > \"Print Preview\" and then print the page to PDF using your browser - remember to enter the Print Preview first).\n",
    "\n",
    "## IMPORTANT\n",
    "\n",
    "1. Do not share your code and answers with others. Contrary to the class exercises, which you can do with others, these problems are *not* group work and must be done individually.\n",
    "2. It is allowed to use snippets of code from the lecture exercises and model solutions.\n",
    "3. It is your responsibility to ensure that the notebook has fully finished running all the cells, all the plots view properly etc. before submitting it. However, the notebook should be runnable from scratch if needed (\"Kernel > Restart & Run All\").\n",
    "4. Submit your work by the deadline.\n",
    "5. Unless stated otherwise, please report your numerical answers in Moodle with full numerical precision (~14-15 digits), unless the answer is an integer.\n",
    "6. If you are confused, think there is a mistake or find things too difficult, please ask on Moodle.\n",
    "\n",
    "## References\n",
    "\n",
    "- \\[**MKG22**\\] Ma WJ, KÃ¶rding K, and Goldreich D. \"Bayesian Models of Perception and Action: An Introduction\". MIT Press, 2022.\n",
    "- \\[**AWV12**\\] Acerbi L, Wolpert DM, Vijayakumar S. \"Internal Representations of Temporal Statistics and Feedback Calibrate Motor-Sensory Interval Timing\". *PLoS Computational Biology*, 2012. [Link](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002771)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up -- do not change\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "npr.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.1 (7 pts)\n",
    "\n",
    "> This question is about computing the total (root mean squared) error (RMSE) for a Bayesian observer, as seen in Week 3 of the course. The take-home message here is that the Bayesian observer whose prior matches the true empirical distribution of stimuli will perform best at the task (lower RMSE), compared to a Bayesian observer with an incorrect (aka *mismatched*) belief about the distribution of stimuli (i.e., whose prior does not match the true stimulus distribution). See Chapter 4.5 of \\[**MKG22**\\] and the lecture notes for Week 3.\n",
    "\n",
    "A Bayesian observer is estimating a stimulus with empirical distribution $p(s) = \\text{Uniform}(s; -5, 5)$.\n",
    "The measurement distribution and likelihood are Gaussian $p(x|s) = \\mathcal{N}\\left(x; s, \\sigma^2 \\right)$ with $\\sigma = 2$.\n",
    "We assume that the observer uses the posterior mean estimator $\\hat{s}_{PM}$ and we ignore response noise. However, we consider the observer uses as prior a distribution $q(s)$ which might differ from the true prior (mismatched prior).\n",
    "\n",
    "- a) Compute the total RMSE assuming $q(s) = p(s)$, i.e. the observer uses the true stimulus distribution as prior.\n",
    "- b) Compute the total RMSE assuming the observer uses an approximate Gaussian prior, $q(s) = \\mathcal{N}\\left(s; \\mu_s, \\sigma_s^2 \\right)$ with mean $\\mu_s$ and variance $\\sigma^2_s$ equal to the mean and variance of the true stimulus distribution. *Hint*: You can find the variance of a continuous uniform distribution [here](https://en.wikipedia.org/wiki/Continuous_uniform_distribution).\n",
    "- c) Compute the total RMSE assuming the observer uses as prior a mismatched, wider Uniform distribution, $q(s) = \\text{Uniform}\\left(s; -8, 8 \\right)$.\n",
    "\n",
    "Report your results in Moodle. The accepted tolerance is $\\pm 0.01$ from the true value.\n",
    "\n",
    "*Hints*: \n",
    "- Remember that the (total) RMSE of an estimator $\\hat{s}$ is computed as\n",
    "$$\n",
    "\\text{RMSE}[\\hat{s}] = \\sqrt{\\int \\text{MSE}\\left[\\hat{s}|s\\right] p(s) ds}\n",
    "$$\n",
    "  where $p(s)$ is the true empirical distribution and $\\text{MSE}\\left[\\hat{s}|s\\right]$ is the mean squared error at each stimulus, defined as\n",
    "$$\n",
    "\\text{MSE}\\left[\\hat{s}|s\\right] = \\mathbb{E}_{\\hat{s}|s}\\left[\\left(\\hat{s}-s\\right)^2|s \\right] = \\text{Bias}\\left[\\hat{s}|s\\right]^2 + \\text{Var}\\left[\\hat{s}|s\\right],\n",
    "$$\n",
    "  where the definitions for bias and variance can be found in the textbook or lecture notes.\n",
    "- Note that changing the prior $q(s)$ will change $\\hat{s}(x)$, but nothing else! So once you manage to compute (a), you should be able to compute (b) and (c) with a small change to the code (only where $\\hat{s}(x)$ is computed).\n",
    "- You may want to check out Exercise 3.3 of the workshops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.2 (6 pts)\n",
    "\n",
    "\n",
    "> In this question, we compute the response distribution for \\[**JS10**\\] under different assumptions about the Bayesian observer.\n",
    "\n",
    "Consider the time perception experiment from \\[**JS10**\\] which we analyzed in Exercise 3.4.\n",
    "We recall the setup below. Note that there are differences from Exercise 3.4 (marked as **NEW**):\n",
    "- In this experiment, an observer is asked to judge the time interval $s$ between two flashes, measured in milliseconds (ms). In each trial, the duration is drawn from an interval distribution $p(s)$. \n",
    "- The experiment consist of three separate blocks of sessions run over multiple days. Each experimental block is identical except for the distribution of intervals $p(s)$. The distribution of time intervals in the three blocks are: \n",
    "  - $p_\\text{short}(s) = \\text{Uniform}\\left(s; 494, 847\\right)$\n",
    "  - $p_\\text{medium}(s) = \\text{Uniform}\\left(s; 671, 1023\\right)$\n",
    "  - $p_\\text{long}(s) = \\text{Uniform}\\left(s; 847,1200\\right)$\n",
    "- The observer's measurement distribution follows *Weber's law* (known in time perception as the \"scalar property\" of temporal judgment). According to this empirical law, the measurement noise is roughly linearly proportional to the magnitude of the stimulus. In formulas, $$p(x|s) = \\mathcal{N}\\left(x|s,\\sigma^2(s)\\right) \\qquad \\text{with} \\quad \\sigma(s) = w_s \\cdot s$$\n",
    "  where $w_s$ is known as *Weber's fraction*. Typical values of $w_s$ in timing are around 0.05-0.2, here we assume $w_s = 0.1$.\n",
    "- It is assumed that, after some practice, the observer develops a prior $p(s)$ which matches the stimulus distribution used in that block of sessions (and that the likelihood also matches the measurement distribution).\n",
    "- **NEW**: The observer responds with a deterministic estimate $\\hat{s}_\\text{MAP}$ which we assume is the mode of the posterior (also known as *maximum-a-posteriori* or MAP estimate). \n",
    "- **NEW**: The response is corrupted by motor noise which is proportional to the estimate:\n",
    "$$p(r|\\hat{s}) = \\mathcal{N}\\left(r; \\hat{s}, \\sigma_\\text{m}^2(\\hat{s})\\right) \\qquad \\text{with} \\quad \\sigma_\\text{m}(\\hat{s}) = w_\\text{m} \\cdot \\hat{s}$$ \n",
    "  where $w_\\text{m}$ represents the Weber's fraction for the motor noise. Here we assume $w_\\text{m} = 0.05$.\n",
    "  \n",
    "-------------------------------\n",
    "\n",
    "In this exercise, we look at the *distribution of responses* $p(r|s)$ that the experimenter would observe for a given stimulus in the three different experimental blocks (short, medium, or long). We consider the stimulus $s^\\star = 847$ ms which appears in all three experimental blocks.\n",
    "\n",
    "- a) Compute $p(r|s = s^\\star)$ for the \"short\" block. Compute the mean and standard deviation of $p(r|s = s^\\star)$ and report them on Moodle.\n",
    "- b) Compute $p(r|s = s^\\star)$ for the \"medium\" block. Compute the mean and standard deviation of $p(r|s = s^\\star)$ and report them on Moodle.\n",
    "- c) Compute $p(r|s = s^\\star)$ for the \"long\" block. Compute the mean and standard deviation of $p(r|s = s^\\star)$ and report them on Moodle.\n",
    "\n",
    "The accepted tolerance for the solutions is $\\pm 0.2$ ms for (a) and (b), and $\\pm 0.5$ ms for (c).\n",
    "\n",
    "*Hints*: \n",
    "- Be careful that the likelihood, $p(x|s)$ as a function of $s$, is *not* Gaussian, because $\\sigma(s)$ is not constant in $s$. As a consequence, the posterior will *not* be Gaussian. This affects the MAP estimate, $\\hat{s}_\\text{MAP}$, which you will need to compute numerically.\n",
    "- To compute the response distribution, remember the definition:\n",
    "$$\n",
    "p(r|s) = \\int p(r|\\hat{s}(x)) p(x|s) dx,\n",
    "$$\n",
    "  which you can solve via numerical integration.\n",
    "- It is recommended that you first compute $\\hat{s}_\\text{MAP}(x)$ for a grid of $x$, and then compute the response distribution numerically via the integral above.\n",
    "- The MAP estimate $\\hat{s}_\\text{MAP}$ is the value of $s$ that maximizes the posterior $p(s|x)$. Note that this value does not depend on the normalization constant, so you can compute $p(s|x) \\propto p(s) p(x|s)$ for a (fine) grid of values `s_grid` and take the argument $s$ that maximizes this quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.3 (6 pts)\n",
    "\n",
    "> The key quantity for model fitting is the log-likelihood for a dataset and some model parameters. In this exercise, we compute the log-likelihood for a Bayesian observer model which also includes the possibility of *lapses*, a common mechanism used in cognitive science to explain away \"random\" responses and subjects' mistakes.\n",
    "\n",
    "In this question, we consider the datasets from Experiment 3 of \\[**AWV12**\\]. The experimental setup which involves time perception and interval reproduction is very similar to \\[**JS10**\\], so we can consider the same type of models.\n",
    "\n",
    "We analyze the data with the `gaussianobserverwithlapse` model, defines as follows:\n",
    "\n",
    "- We assume the observer builds a (mismatched) Gaussian prior $p(s) = \\mathcal{N}\\left(s| \\mu_\\text{prior}, \\sigma_\\text{prior}^2 \\right)$ over the stimuli (time intervals). \n",
    "- We assume that the measurement distribution and likelihood are also Gaussian, $p(x|s) = \\mathcal{N}\\left(x| s, \\sigma^2 \\right)$.\n",
    "- The observer uses the *posterior mean* estimator for the value of the stimulus, $\\hat{s}_\\text{PM}$.\n",
    "- Gaussian motor response noise is added to the estimate, $p(r|\\hat{s}) = \\mathcal{N}\\left(r| \\hat{s}, \\sigma_\\text{motor}^2 \\right)$.\n",
    "- In each trial, the observer lapses with probability $\\lambda$ (the *lapse rate*), in which case the response is drawn from $p_\\text{lapse}(r) = \\text{Uniform}\\left(r; 0, 1500 \\right)$ ms. Otherwise, the observer responds normally (according to $p(r|\\hat{s})$ described above) with probability $1 - \\lambda$. \n",
    "- The parameters of this model are $\\mathbf{\\theta} = \\left(\\mu_\\text{prior}, \\sigma_\\text{prior}, \\sigma, \\sigma_\\text{motor}, \\lambda \\right)$.\n",
    "\n",
    "For this question, we consider parameters $\\mathbf{\\theta}_\\star = \\left(\\mu_\\text{prior} = 780, \\sigma_\\text{prior} = 140, \\sigma = 90, \\sigma_\\text{motor} = 60, \\lambda = 0.02 \\right)$. \n",
    "\n",
    "- a) Compute the log-likelihood of model parameter $\\theta_\\star$ for the dataset of subject 2.\n",
    "- b) Compute the log-likelihood of model parameter $\\theta_\\star$ for the dataset of subject 5.\n",
    "\n",
    "Report your results on Moodle with high precision.\n",
    "\n",
    "*Hint*:\n",
    "- If you use code from the lectures, be careful about the model definition, as there may be subtle differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject id</th>\n",
       "      <th>Session id</th>\n",
       "      <th>Run id</th>\n",
       "      <th>Stimulus (ms)</th>\n",
       "      <th>Response (ms)</th>\n",
       "      <th>Stimulus id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>973.327049</td>\n",
       "      <td>862.947945</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>677.519900</td>\n",
       "      <td>574.920276</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>826.253049</td>\n",
       "      <td>870.995615</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>677.854859</td>\n",
       "      <td>695.055098</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>598.501198</td>\n",
       "      <td>632.981845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject id  Session id  Run id  Stimulus (ms)  Response (ms)  Stimulus id\n",
       "0           1           1       1     973.327049     862.947945          6.0\n",
       "1           1           1       1     677.519900     574.920276          2.0\n",
       "2           1           1       1     826.253049     870.995615          4.0\n",
       "3           1           1       1     677.854859     695.055098          2.0\n",
       "4           1           1       1     598.501198     632.981845          1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data of Experiment 3 of [AWV12] from .csv file to a Pandas dataframe\n",
    "df = pd.read_csv('https://www2.helsinki.fi/sites/default/files/atoms/files/awv12_exp3.csv')\n",
    "\n",
    "# Remove unused columns (they deal with performance feedback, which we ignore in this lecture)\n",
    "df.drop(df.columns[[6, 7, 8]], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with NaNs\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.shape: (2520,)\n",
      "r.shape: (2520,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example code to extract stimuli and responses for a single subject (here subject 1)\n",
    "subject = 1\n",
    "s = np.array(df['Stimulus (ms)'][df['Subject id'] == subject])\n",
    "r = np.array(df['Response (ms)'][df['Subject id'] == subject])\n",
    "print('s.shape:', s.shape)\n",
    "print('r.shape:', r.shape)\n",
    "\n",
    "plt.scatter(s, r)\n",
    "plt.xlabel('s (ms)')\n",
    "plt.ylabel('r (ms)')\n",
    "plt.title('Responses (subject ' + str(subject) + ')')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.4 (6 pts)\n",
    "\n",
    "> When fitting models to data, the experimenter may be interested in how model parameters are represented across the population (here represented by the group of subjects). A simple way to look at this is to look at the distribution of maximum-likelihood estimates for the parameters across subjects, in first instance by looking their mean and variability.\n",
    "\n",
    "We consider here the `idealgaussianobserverwithlapse` model. This model is the same as the `gaussianobserverwithlapse` of Question 2.3, but with $\\mu_\\text{prior} = 787.5$ ms and $\\sigma_\\text{prior} = 128.1$ ms fixed. Thus, the model has three free parameters, $\\theta = \\left(\\sigma, \\sigma_\\text{motor}, \\lambda \\right)$. Fit the model using maximum-likelihood estimation.\n",
    "\n",
    "- a) First, fit the `idealgaussianobserverwithlapse` model to the six subjects' datasets (separately for each subject's data). For each maximum-likelihood estimate (MLE) of parameters $\\sigma, \\sigma_\\text{motor}, \\lambda$, report in Moodle the mean and standard deviation across the six subjects. For the standard deviation, use the correction for degrees of freedom (that is, `np.std(..., ddof=1)`).\n",
    "- b) Now fit the pooled data of all subjects as a single dataset (as if all data were collected from a single uber-subject). Report the maximum-likelihood estimate of $\\sigma, \\sigma_\\text{motor}, \\lambda$ for the pooled data in Moodle.\n",
    "\n",
    "*Hints*: \n",
    "- If you use code for the `idealgaussianobserverwithlapse` model from the lectures, be careful about the model definition.\n",
    "- As a sanity check that you have coded the log-likelihood function correctly, check that the log-likelihood of the dataset of subject 1 for $\\theta_\\star = \\left(\\sigma = 90, \\sigma_\\text{motor} = 80, \\lambda = 0.02\\right)$ is $\\log \\mathcal{L}(\\theta_\\star; \\mathcal{D}_1) \\approx -14709.795\\ldots$\n",
    "\n",
    "*Note*: Fitting individual subjects' data is the best approach to describe invidual behavior in cognitive science, but sometimes you will see studies only looking at pooled/group data. Be careful that pooling might hide what really happens, only giving a snapshot of the average behavior of the group, which might not correspond to what individuals do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

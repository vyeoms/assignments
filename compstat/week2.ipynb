{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Mathematics and Statistics  \n",
    "MAST32001 Computational Statistics, Autumn 2022  \n",
    "Luigi Acerbi  \n",
    "\n",
    "# Week 2 exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Permutation testing (6 pts)\n",
    "\n",
    "We will use permutation testing to study if the mother's age (`age`) affects the birth weight (`bwt`) of their babies. We will use the absolute difference in the means as the test statistic. We will focus the analysis on full term pregnancies (`gestation >= 273`).\n",
    "\n",
    "*Note*: When reporting a $p$-value for $b$ more extreme tests out of $m$, use $p = (b+1)/(m+1)$ to avoid zero p-values. 50000 permutations will be sufficient for obtaining the required accuracy.\n",
    "\n",
    "1. Load the data set below. Test whether the birth weights (`bwt`) of babies with young (`age < 26`) and older (`age >= 26`) mothers are statistically significantly different using the difference of the means as the test statistic. Report the $p$-value you obtain in Moodle.\n",
    "2. Stratify the analysis by the variable smoking status of the mothers by splitting to separate smoker (`smoke = 0`) and non-smoker (`smoke = 1`) groups. Constrain the permutations so that only changes within each group are allowed. After the permutation, merge the two groups back together to compute the means. Report the $p$-value you obtain in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value without stratification =  0.0751584968300634\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "# Load the data set\n",
    "babies_full = pd.read_csv(\"https://www2.helsinki.fi/sites/default/files/atoms/files/babies2.txt\", sep='\\t')\n",
    "\n",
    "# Pick a subset\n",
    "babies1 = babies_full.iloc[(babies_full['gestation']>=273).values]\n",
    "\n",
    "def shuffle(x1, x2):\n",
    "    \"\"\"Return a random reshuffling of elements in two arrays\"\"\"\n",
    "    n1 = len(x1)\n",
    "    z = npr.permutation(np.concatenate((x1, x2)))\n",
    "    return z[0:n1], z[n1:]\n",
    "\n",
    "def merge(x1, x2):\n",
    "    \"\"\"Merge two data sets\"\"\"\n",
    "    return np.concatenate((x1, x2))\n",
    "\n",
    "def permutation_test_absmeandiff(x1, x2, N_perm):\n",
    "    \"\"\"Perform permutation test for the absolute mean difference of two groups.\"\"\"\n",
    "    truediff = np.abs(np.mean(x1) - np.mean(x2))\n",
    "    meandiffs = np.zeros(N_perm)\n",
    "    for i in range(N_perm):\n",
    "        z1, z2 = shuffle(x1, x2)\n",
    "        meandiffs[i] = np.abs(np.mean(z1) - np.mean(z2))\n",
    "    return (np.sum(truediff <= meandiffs)+1)/(len(meandiffs)+1)\n",
    "\n",
    "def permutation_test_stratified_absmeandiff(x1a, x1b, x2a, x2b, N_perm):\n",
    "    \"\"\"Perform permutation test for the absolute mean difference of two groups with stratification.\"\"\"\n",
    "    truediff = np.abs(np.mean(merge(x1a, x1b)) - np.mean(merge(x2a, x2b)))\n",
    "    meandiffs = np.zeros(N_perm)\n",
    "    for i in range(N_perm):\n",
    "        # Shuffle two subgroups independently\n",
    "        z1a, z2a = shuffle(x1a, x2a)\n",
    "        z1b, z2b = shuffle(x1b, x2b)\n",
    "        # Re-merge the two subgroups for each unit\n",
    "        z1 = merge(z1a, z1b)\n",
    "        z2 = merge(z2a, z2b)\n",
    "        # Compute the difference as usual\n",
    "        meandiffs[i] = np.abs(np.mean(z1) - np.mean(z2))\n",
    "    return (np.sum(truediff <= meandiffs)+1)/(len(meandiffs)+1)\n",
    "\n",
    "### Part 1\n",
    "Iyounger = ( babies1['age'] < 26 ).values\n",
    "Iolder = ( babies1['age'] >= 26 ).values\n",
    "\n",
    "younger_vals = babies1['bwt'].values[Iyounger]\n",
    "older_vals = babies1['bwt'].values[Iolder]\n",
    "\n",
    "npr.seed(0)\n",
    "pval = permutation_test_absmeandiff(younger_vals, older_vals, 50000)\n",
    "print(\"p-value without stratification = \", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value with stratification =  0.07897842043159137\n"
     ]
    }
   ],
   "source": [
    "Iyounger = ( babies1['age'] < 26 ).values\n",
    "Iolder = ( babies1['age'] >= 26 ).values\n",
    "smoker = ( babies1['smoke'] == 1 ).values\n",
    "non_smoker = ( babies1['smoke'] == 0 ).values\n",
    "\n",
    "younger_smoker = babies1['bwt'].values[Iyounger & smoker]\n",
    "younger_non_smoker = babies1['bwt'].values[Iyounger & non_smoker]\n",
    "older_smoker = babies1['bwt'].values[Iolder & smoker]\n",
    "older_non_smoker = babies1['bwt'].values[Iolder & non_smoker]\n",
    "\n",
    "npr.seed(0)\n",
    "pval = permutation_test_stratified_absmeandiff(younger_smoker, younger_non_smoker, \\\n",
    "                                               older_smoker, older_non_smoker, 50000)\n",
    "print(\"p-value with stratification = \", pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bootstrap confidence intervals on data statistics (4 pts)\n",
    "\n",
    "In this exercise we use bootstrap to estimate confidence intervals for various quantities. (Using 1000 bootstrap samples will give you enough accuracy assuming everything is correctly done.)\n",
    "\n",
    "1. Use bootstrap to estimate the central 95% confidence interval for the mean of `bwt` in the *full* data set loaded in Problem 1. Report the lower and upper ends of the interval in Moodle.\n",
    "2. Use bootstrap to estimate the central 95% confidence interval for the mean of `bwt` in the smaller subset (`gestation >= 273`) of the data set used in Problem 1. Report the lower and upper ends of the interval in Moodle.\n",
    "3. Use bootstrap to estimate the central 95% confidence interval for the correlation coefficient of `gestation` and `age` in the full data set loaded in Problem 1. What does this tell about the relation between the duration of the pregnancy and the age of the mother? Report the bounds of the interval in Moodle.\n",
    "4. Use bootstrap to estimate the central 95% confidence interval for the correlation coefficient of `gestation` and `age` in the smaller subset (`gestation >= 273`) used in Problem 1. What does this tell about the relation between the duration of the pregnancy and the age of the mother? Report the bounds of the interval in Moodle.\n",
    "\n",
    "*Hint*: Remember that the size of the bootstrap sample is always the same as the size of the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. bootstrap interval: [118.34590793 120.50758738]\n",
      "2. bootstrap interval: [122.52281609 124.64827586]\n",
      "3. bootstrap interval: [-0.1097222   0.00104757]\n",
      "4. bootstrap interval: [-0.09141982  0.04007667]\n"
     ]
    }
   ],
   "source": [
    "npr.seed(0)\n",
    "bwt = babies_full['bwt']\n",
    "n_bootstrap = 1000\n",
    "n = len(bwt)\n",
    "bootstrap_means = np.array([np.mean(npr.choice(bwt, replace=True, size=n)) for i in range(n_bootstrap)])\n",
    "print('1. bootstrap interval:', np.percentile(bootstrap_means, [2.5, 97.5]))\n",
    "\n",
    "bwt_gest = babies1['bwt']\n",
    "n_bootstrap = 1000\n",
    "n = len(bwt_gest)\n",
    "bootstrap_means = np.array([np.mean(npr.choice(bwt_gest, replace=True, size=n)) for i in range(n_bootstrap)])\n",
    "print('2. bootstrap interval:', np.percentile(bootstrap_means, [2.5, 97.5]))\n",
    "\n",
    "n_bootstrap = 1000\n",
    "corr_coefs = np.zeros(n_bootstrap)\n",
    "n = len(babies_full)\n",
    "for i in range(n_bootstrap):\n",
    "    sample = babies_full.sample(n=n, replace=True)\n",
    "    corr_coefs[i] = np.corrcoef( sample['gestation'], sample['age'] )[0,1]\n",
    "print('3. bootstrap interval:', np.percentile(corr_coefs, [2.5, 97.5]))\n",
    "\n",
    "n_bootstrap = 1000\n",
    "corr_coefs = np.zeros(n_bootstrap)\n",
    "n = len(babies1)\n",
    "for i in range(n_bootstrap):\n",
    "    sample = babies1.sample(n=n, replace=True)\n",
    "    corr_coefs[i] = np.corrcoef( sample['gestation'], sample['age'] )[0,1]\n",
    "print('4. bootstrap interval:', np.percentile(corr_coefs, [2.5, 97.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bootstrap confidence intervals on parameter estimates (4 pts)\n",
    "\n",
    "In this task, we will use bootstrap to obtain confidence intervals on maximum likelihood parameter estimates for linear regression models. We will apply simple case resampling, i.e. resampling the individuals and then fitting the model using the data $(x_i, y_i)$ from these individuals. There are alternative methods that may work better when the data are limited, but in our case there are enough observations so that this will not be a problem. 1000 bootstrap samples will again give you enough accuracy.\n",
    "\n",
    "A linear regression fit to scalar $x_i, y_i$ involves fitting the model\n",
    "$$ y_i = \\alpha + \\beta x_i + \\epsilon_i, $$\n",
    "where $\\beta$ is the regression coefficient and $\\alpha$ is the intercept. Assuming $\\epsilon_i \\sim N(0, \\sigma^2)$, the log-likelihood of the model is\n",
    "$$ \\log p(Y | X, \\alpha, \\beta) = \\sum_{i=1}^n \\log p(y_i | x_i, \\alpha, \\beta)\n",
    "  = \\sum_{i=1}^n - \\frac{1}{2 \\sigma^2} (y_i - \\alpha - \\beta x_i)^2 + C, $$\n",
    "where $C$ is independent of $\\alpha, \\beta$. This is maximised when\n",
    "$$ \\hat{\\beta}= \\frac{\\sum_{i = 1}^n (x_i - \\bar{x})(y_i - \\bar{y}) }{ \\sum_{i = 1}^n (x_i - \\bar{x})^2} \\\\\n",
    "   \\hat{\\alpha} = \\bar{y} - \\hat{\\beta} \\bar{x},$$\n",
    "where $\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n x_i$ and $\\bar{y} = \\frac{1}{n} \\sum_{i = 1}^n y_i$.\n",
    "\n",
    "1. Implement the above linear regression model to predict `gestation` ($y$) as a function of `age` ($x$) in the full data set. Report the estimated $\\beta$ in Moodle.\n",
    "2. Use bootstrap to estimate the confidence interval of the regression coefficient $\\beta$ in the above model by resampling the individuals used to fit the model. Report the lower and upper bounds of the central 95% confidence interval of $\\beta$ in Moodle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated beta:  -0.14772779151120366\n",
      "bootstrap interval: [-0.30191935  0.01800218]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "# Load the data set\n",
    "babies_full = pd.read_csv(\"https://www2.helsinki.fi/sites/default/files/atoms/files/babies2.txt\", sep='\\t')\n",
    "\n",
    "babies3 = babies_full\n",
    "\n",
    "def estimator(x, y):\n",
    "    n = len(x)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    num = 0\n",
    "    den = 0\n",
    "    for i in range(n):\n",
    "        num += (x[i] - x_mean)*(y[i] - y_mean)\n",
    "        den += (x[i] - x_mean)**2\n",
    "    beta = num / den\n",
    "#     alpha = y_mean - beta*x_mean\n",
    "    return beta\n",
    "\n",
    "beta = estimator(babies3['age'].values, babies3['gestation'].values)\n",
    "print(\"Estimated beta: \", beta)\n",
    "\n",
    "n_bootstrap = 1000\n",
    "betas = np.zeros(n_bootstrap)\n",
    "n = len(babies3)\n",
    "for i in range(n_bootstrap):\n",
    "    sample = babies3.sample(n=n, replace=True)\n",
    "    betas[i] = estimator( sample['age'].values, sample['gestation'].values )\n",
    "print('bootstrap interval:', np.percentile(betas, [2.5, 97.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Density estimation (6 pts)\n",
    "\n",
    "1. Estimate the joint density of `bwt` and `age` in the full data set using kernel density estimation with a 2-dimensional Gaussian kernel\n",
    "$$ K(\\mathbf{x}) = \\frac{1}{2\\pi} \\exp\\left( - \\frac{\\|\\mathbf{x}\\|^2}{2} \\right)\n",
    " = \\frac{1}{2\\pi} \\exp\\left( - \\frac{x_1^2 + x_2^2}{2} \\right) $$\n",
    "using bandwidth $h=5$. Report the value of the estimated density at point `bwt=110`, `age=31` in Moodle.\n",
    "\n",
    "*Hint*: you can verify your results by ploting a 2D histogram of the data (`matplotlib.pyplot.hist2d`) and a contour plot of the estimated density (see e.g. Sec. 5.1.1 in Course notes for a contour plot example).\n",
    "\n",
    "2. With the Gaussian kernel above, use leave-one-out (LOO) cross validation to find the optimal $h$ in the range `np.linspace(1.0, 5.0, 50)`. The optimal $h$ maximizes the LOO log-likelihood. Report the value of $h$ and the value of the estimated density at `bwt=110`, `age=31` in Moodle.\n",
    "\n",
    "3. Use $k$-fold cross validation with $k=17$ to find the optimal $h$ in the range `np.linspace(1.0, 5.0, 50)`. Report the value of $h$ and the value of the estimated density at `bwt=110`, `age=31` in Moodle. For this exercise, the sample point indices for the $k$ partitions of the data should consist of consecutive indices, e.g. the first partition should be the data with indices `0:69` and so on. (In practical applications it is generally good practice to randomly permute the indices as well when creating partitions, but don't do it for this exercise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated density at bwt=110, age=31:  0.0007101226311425995\n",
      "Estimated density with optimal LOOCV h=2.3061224489795915 at bwt=110, age=31 is: 0.0005836157630220638\n",
      "Estimated density with K-fold CV h=2.387755102040816 at bwt=110, age=31 is: 0.000592793787708447\n"
     ]
    }
   ],
   "source": [
    "def K_mvgauss(x):\n",
    "    \"\"\"Multivariate normal kernel.\"\"\"\n",
    "    return 1/(2*np.pi) * np.exp(-0.5*np.sum(x**2, 1))\n",
    "\n",
    "def kernel_density_KCV(t, x, h):\n",
    "    y = np.zeros(len(t))\n",
    "    d = x.shape[1]\n",
    "    for i in range(len(t)):\n",
    "        y[i] = np.mean(K_mvgauss((t[i] - x)/ h)) / h**d\n",
    "    return y\n",
    "\n",
    "def mv_kernel_density(t, x, h):\n",
    "    \"\"\"Multivariate normal kernel density estimate.\"\"\"\n",
    "    d = x.shape[1]\n",
    "    return np.mean(K_mvgauss((t - x)/h))/h**d\n",
    "\n",
    "### Part 1\n",
    "data = babies_full[['bwt', 'age']].values\n",
    "observation = np.array([110, 31])\n",
    "h = 5\n",
    "\n",
    "print('Estimated density at bwt=110, age=31: ', mv_kernel_density(observation, data, h))\n",
    "\n",
    "### Part 2\n",
    "def mv_loocv_kernel_density(x, hs):\n",
    "    \"\"\"Multivariate kernel density estimation via leave-one-out cross-validation \"\"\"\n",
    "    logls = np.zeros(len(hs))\n",
    "    for j in range(len(x)):\n",
    "        train_x = np.delete(x, j, axis=0) # Remove the j-th point\n",
    "        test_x = np.array([x[j]]) # Single test point\n",
    "        for i in range(len(hs)):\n",
    "            logls[i] += np.log(mv_kernel_density(test_x, train_x, hs[i]))\n",
    "    # print('LOO log-probabilities:', logls)\n",
    "    return hs[np.argmax(logls)]\n",
    "\n",
    "hs = np.linspace(1.0, 5.0, 50)\n",
    "optimal_h = mv_loocv_kernel_density(data, hs)\n",
    "estimate_opt_h = mv_kernel_density(observation, data, optimal_h)\n",
    "print(f'Estimated density with optimal LOOCV h={optimal_h} at bwt=110, age=31 is: {estimate_opt_h}')\n",
    "\n",
    "### Part 3\n",
    "npr.seed(0)\n",
    "def k_foldcv(x, k, hs):\n",
    "    \"\"\"K-fold cross-validation.\"\"\"\n",
    "    N = len(x)\n",
    "    I = npr.permutation(N)\n",
    "    logls = np.zeros(len(hs))\n",
    "    for j in range(k):\n",
    "        testI = np.zeros(N, bool)\n",
    "        testI[((j*N)//k):(((j+1)*N)//k)] = True\n",
    "        trainI = ~testI\n",
    "        for i in range(len(hs)):\n",
    "            logls[i] += np.sum(np.log(kernel_density_KCV(x[I[testI]], x[I[trainI]], hs[i])))\n",
    "    return (hs, logls)\n",
    "\n",
    "k = 17\n",
    "hs, logls = k_foldcv(data, k, hs)\n",
    "opt_k_h = hs[np.argmax(logls)]\n",
    "estimate_k_opt_h = mv_kernel_density(observation, data, opt_k_h)\n",
    "print(f'Estimated density with K-fold CV h={opt_k_h} at bwt=110, age=31 is: {estimate_k_opt_h}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
